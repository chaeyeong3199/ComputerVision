# ğŸ“Œ L06: Local Feature

## ğŸ“ ê³¼ì œ ë‚´ìš©

### 1. SIFTë¥¼ ì´ìš©í•œ íŠ¹ì§•ì  ê²€ì¶œ ë° ì‹œê°í™”
   **1. ì´ë¯¸ì§€ ë¡œë“œ ë° ê·¸ë ˆì´ ìŠ¤ì¼€ì¼ ë³€í™˜**
   ```python
  img=cv.imread('L06\img\mot_color70.jpg')
  gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
   ```
   **2. SIFT ê°ì²´ ìƒì„±**

   ```python
  sift=cv.SIFT_create(nfeatures=1000)
   ```
   - **SIFT(Scale-Invariant Feature Transform)** : ì´ë¯¸ì§€ì˜ í¬ê¸°(scale) ë° íšŒì „(rotation)ì— ì˜í–¥ì„ ë°›ì§€ ì•ŠëŠ” íŠ¹ì§•ì ì„ ì¶”ì¶œí•˜ëŠ” ì•Œê³ ë¦¬ì¦˜
   - nfeatureê°’(ìµœëŒ€ íŠ¹ì§•ì  ìˆ˜)ì„ 1000ê°œë¡œ ì§€ì •
     
   **3. detectAndCompute()ë¥¼ í†µí•´ íŠ¹ì§•ì  ê²€ì¶œ**

   ```python
  kp,des=sift.detectAndCompute(gray,None)
   ```
   - **cv2.Feature2D.detectAndCompute(image, mask=None)**: íŠ¹ì§•ì  ê²€ì¶œê³¼ íŠ¹ì§• ë””ìŠ¤í¬ë¦½í„° ê³„ì‚°ì„ í•œ ë²ˆì— ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
   - image: ì…ë ¥ ì´ë¯¸ì§€, mask: íŠ¹ì§•ì  ê²€ì¶œì— ì‚¬ìš©í•  ë§ˆìŠ¤í¬
     
   **4. drawKeypoints()ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§•ì ì„ ì´ë¯¸ì§€ì— ì‹œê°í™”**
   
   ```python
  gray=cv.drawKeypoints(gray,kp,None,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
   ```
   - **cv2.drawKeypoints(image, keypoints, outImage, color=None, flags=None)** 
   - image: ì…ë ¥ ì˜ìƒ, keypoints: ê²€ì¶œëœ íŠ¹ì§•ì  ì •ë³´, outImage: ì¶œë ¥ ì˜ìƒ
   - flags: íŠ¹ì§•ì  í‘œí˜„ ë°©ë²• -> DEFAULT(ìœ„ì¹˜ë§Œ í‘œí˜„), **DRAW_RICH_KEYPOINTS(í¬ê¸°ì™€ ë°©í–¥ì„ ë°˜ì˜)**
   - íŠ¹ì§•ì (ì›)ì˜ í¬ê¸°: ì´ë¯¸ì§€ì—ì„œ ê²€ì¶œëœ Scaleì— ë”°ë¼ ë‹¤ë¦„ <br>
     ì‘ì€ í¬ê¸°ì˜ íŠ¹ì§•ì  â†’ ì„¸ë°€í•œ íŠ¹ì§• (ì˜ˆ: í…ìŠ¤ì²˜ê°€ ë§ì€ ì˜ì—­) <br>
     í° í¬ê¸°ì˜ íŠ¹ì§•ì  â†’ í° êµ¬ì¡°ì ì¸ íŠ¹ì§• (ì˜ˆ: ì½”ë„ˆ, ì—£ì§€ ë“±)
     
  <details>
     <summary>ì „ì²´ì½”ë“œ</summary>
     
   ```python
      import cv2 as cv
      import matplotlib.pyplot as plt

      img=cv.imread('L06\img\mot_color70.jpg')
      gray=cv.cvtColor(img,cv.COLOR_BGR2GRAY)

      sift=cv.SIFT_create(nfeatures=1000)
      kp,des=sift.detectAndCompute(gray,None)

      gray=cv.drawKeypoints(gray,kp,None,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

      fig, axes = plt.subplots(1, 2, figsize=(15,5))
      axes[0].imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))
      axes[0].set_title("Original Image")
      axes[0].axis("off")

      axes[1].imshow(gray)
      axes[1].set_title("SIFT Image")
      axes[1].axis("off")
      plt.tight_layout()
      plt.show()
   ```
  </details>

  #### ê²°ê³¼ì´ë¯¸ì§€
   ![image](https://github.com/user-attachments/assets/df02c968-9d3d-461c-ae76-6e53dcb1abb1)

     
### 2. SIFTë¥¼ ì´ìš©í•œ ë‘ ì˜ìƒ ê°„ íŠ¹ì§•ì  ë§¤ì¹­
   **1. ë‘ ì´ë¯¸ì§€ì˜ SIFT íŠ¹ì§•ì  ì¶”ì¶œ**
   ```python
  sift=cv.SIFT_create()
  kp1,des1=sift.detectAndCompute(gray1,None)
  kp2,des2=sift.detectAndCompute(gray2,None)
   ```

   **2-1. FlannBasedMatcher()ì„ í†µí•´ íŠ¹ì§•ì  ë§¤ì¹­**
   ```python
   index_params = dict(algorithm=1, trees=5)
   search_params = dict(checks=50)
   flann_matcher=cv.FlannBasedMatcher(index_params, search_params)
   ```
   - **cv2.FlannBasedMatcher(indexParams, searchParams)**: FLANN (Fast Library for Approximate Nearest Neighbors) ê¸°ë°˜ Matcher ìƒì„±
   - index_params: íŠ¹ì§•ì  ê²€ìƒ‰ì„ ìœ„í•œ êµ¬ì¡° ì„¤ì • (KD-Tree ì‚¬ìš©)
   - search_params: ê²€ìƒ‰ ê³¼ì •ì—ì„œ ê³ ë ¤í•  ì´ì›ƒ ê°œìˆ˜ ì„¤ì •

   **2-2. BFMatcher()ì„ í†µí•´ íŠ¹ì§•ì  ë§¤ì¹­**
   ```python
  bf_matcher=cv.BFMatcher(cv.NORM_L2, crossCheck=False)
  bf_match=bf_matcher.knnMatch(des1, des2, 2)
   ```

   **3. ìµœê·¼ì ‘ ì´ì›ƒ ê±°ë¦¬ ë¹„ìœ¨ì„ ì ìš©í•œ KNN ë§¤ì¹­**

   ```python
   knn_match=flann_matcher.knnMatch(des1,des2,2)
   T=0.7
   good_match=[]
   for nearest1,nearest2 in knn_match:
      if (nearest1.distance/nearest2.distance)<T:
         good_match.append(nearest1)
   ```
   - **knnMatch(descripter1,descripter2,k)** : ê° descripterë¥¼ ë¹„êµí•´ kê°œì˜ ìµœê·¼ì ‘ ì´ì›ƒì„ ì°¾ìŒ
   - T=0.7: ê±°ë¦¬ê°€ ê°€ê¹Œìš´ ë‘ ì ì˜ ë¹„ìœ¨ì´ 0.7 ì´í•˜ì¸ ê²½ìš° ì¢‹ì€ ë§¤ì¹­

   **4. drawMatches()ë¥¼ í†µí•´ ë§¤ì¹­ ê²°ê³¼ë¥¼ ì‹œê°í™”**

   ```python
   img_match=np.empty((max(img1.shape[0],img2.shape[0]),img1.shape[1]+img2.shape[1],3),dtype=np.uint8)
   cv.drawMatches(img1,kp1,img2,kp2,good_match,img_match,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
   ```
   - np.empty(): ë‘ ì´ë¯¸ì§€ë¥¼ ë‚˜ë€íˆ ë°°ì¹˜í•˜ê¸° ìœ„í•´ ë¹ˆ ë°°ì—´ì„ ìƒì„±
   - **cv.drawMatches()**: ë§¤ì¹­ëœ íŠ¹ì§•ì ì„ ì‹œê°ì ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ì¶œë ¥

  <details>
     <summary>ì „ì²´ì½”ë“œ</summary>
     
   ```python
   import cv2 as cv
   import numpy as np
   import matplotlib.pyplot as plt
   
   img1=cv.imread('L06\img\mot_color70.jpg')[190:350,440:560]
   gray1=cv.cvtColor(img1,cv.COLOR_BGR2GRAY)
   img2=cv.imread('L06\img\mot_color83.jpg')
   gray2=cv.cvtColor(img2,cv.COLOR_BGR2GRAY)
   
   sift=cv.SIFT_create()
   kp1,des1=sift.detectAndCompute(gray1,None)
   kp2,des2=sift.detectAndCompute(gray2,None)
   
   index_params = dict(algorithm=1, trees=5)
   search_params = dict(checks=50)
   
   flann_matcher=cv.FlannBasedMatcher(index_params, search_params)
   knn_match=flann_matcher.knnMatch(des1,des2,2)
   
   T=0.7
   good_match=[]
   for nearest1,nearest2 in knn_match:
       if (nearest1.distance/nearest2.distance)<T:
           good_match.append(nearest1)
   
   img_match=np.empty((max(img1.shape[0],img2.shape[0]),img1.shape[1]+img2.shape[1],3),dtype=np.uint8)
   cv.drawMatches(img1,kp1,img2,kp2,good_match,img_match,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
   
   plt.figure(figsize=(10,5))
   plt.imshow(cv.cvtColor(img_match, cv.COLOR_BGR2RGB))
   plt.title("Matching Result")
   plt.axis("off")
   plt.tight_layout()
   plt.show()
   ```
  </details>

  #### ê²°ê³¼ì´ë¯¸ì§€ 
  ![image](https://github.com/user-attachments/assets/1da00a6d-f605-46f1-9150-65fe6e1ef4ff)

   
### 3. í˜¸ëª¨ê·¸ë˜í”¼ë¥¼ ì´ìš©í•œ ì´ë¯¸ì§€ ì •í•© (Image Alignment)
   **1. ë‘ ì´ë¯¸ì§€ì˜ SIFT íŠ¹ì§•ì  ì¶”ì¶œ**
   ```python
   sift=cv.SIFT_create()
   kp1,des1=sift.detectAndCompute(gray1,None)
   kp2,des2=sift.detectAndCompute(gray2,None)
   ```

   **2. BFMatcher()ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§•ì ì„ ë§¤ì¹­**

   ```python
   bf_matcher=cv.BFMatcher(cv.NORM_L2, crossCheck=False)
   bf_match=bf_matcher.knnMatch(des1, des2, 2)
   ```
   - **cv.BFMatcher(normType, crossCheck)**: Brute-Force ë°©ì‹ì˜ Matcher ìƒì„±
   - cv.NORM_L2: SIFTì™€ ê°™ì€ floatí˜• descripterì— ì í•©í•œ ê±°ë¦¬ ì¸¡ì • ë°©ì‹
   - crossCheck=False: KNN ë§¤ì¹­ì„ ì‚¬ìš©í•˜ë¯€ë¡œ í•„ìš”X

   **3. findHomography()ë¥¼ í†µí•´ í˜¸ëª¨ê·¸ë˜í”¼ í–‰ë ¬ì„ ê³„ì‚°**

   ```python
   points1=np.float32([kp1[gm.queryIdx].pt for gm in good_match])
   points2=np.float32([kp2[gm.trainIdx].pt for gm in good_match])

   H, mask = cv.findHomography(points2, points1, cv.RANSAC)
   ```
   - np.float32(): íŠ¹ì§•ì  ì¢Œí‘œë¥¼ ì‹¤ìˆ˜í˜• ë°°ì—´ë¡œ ë³€í™˜
   - **cv.findHomography(srcPoints, dstPoints, method)**: RANSACì„ ì‚¬ìš©í•˜ì—¬ ë³€í™˜ í–‰ë ¬ Hë¥¼ ê³„ì‚° -> outlier ì œê±°
   - ë‘ ë²ˆì§¸ ì´ë¯¸ì§€(img2)ë¥¼ ë³€í™˜í•´ ì²« ë²ˆì§¸ ì´ë¯¸ì§€(img1)ì— ì •ë ¬í•˜ê¸° ìœ„í•´ points2 â†’ points1 ìˆœì„œë¡œ ì‚¬ìš©

   **4. ì´ë¯¸ì§€ë¥¼ ë³€í™˜í•˜ì—¬ ë‹¤ë¥¸ ì´ë¯¸ì§€ì™€ ì •ë ¬**

   ```python
  h1, w1 = img1.shape[:2]
  h2, w2 = img2.shape[:2]
  
  warp = cv.warpPerspective(img2, H, (w1 + w2, h2))
  warp[0:h1, 0:w1] = img1
   ```
   - ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ë¥¼ í˜¸ëª¨ê·¸ë˜í”¼ í–‰ë ¬ Hì„ ì´ìš©í•˜ì—¬ íˆ¬ì‹œ ë³€í™˜(perspective transformation) ìˆ˜í–‰.
   - ë³€í™˜ëœ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ (w1 + w2, h2)ë¡œ ì„¤ì •í•˜ì—¬, ë³‘í•©í•  ì¶©ë¶„í•œ ê³µê°„ì„ í™•ë³´.
   - warp[0:h1, 0:w1] = img1 : ë³€í™˜ëœ warpì˜ ì™¼ìª½ì— img1ì„ ì‚½ì…í•˜ì—¬ ë‘ ì´ë¯¸ì§€ë¥¼ ì •ë ¬.

  <details>
     <summary>ì „ì²´ì½”ë“œ</summary>
     
   ```python
  import cv2 as cv
  import numpy as np
  import matplotlib.pyplot as plt
  
  img1=cv.imread('L06\img\img2.jpg')
  gray1=cv.cvtColor(img1,cv.COLOR_BGR2GRAY)
  img2=cv.imread('L06\img\img3.jpg')
  gray2=cv.cvtColor(img2,cv.COLOR_BGR2GRAY)
  
  sift=cv.SIFT_create()
  kp1,des1=sift.detectAndCompute(gray1,None)
  kp2,des2=sift.detectAndCompute(gray2,None)
  
  bf_matcher=cv.BFMatcher(cv.NORM_L2, crossCheck=False)
  bf_match=bf_matcher.knnMatch(des1, des2, 2)
  
  T=0.7
  good_match=[]
  for nearest1,nearest2 in bf_match:
      if (nearest1.distance/nearest2.distance)<T:
          good_match.append(nearest1)
  
  points1=np.float32([kp1[gm.queryIdx].pt for gm in good_match])
  points2=np.float32([kp2[gm.trainIdx].pt for gm in good_match])
  
  H, mask = cv.findHomography(points2, points1, cv.RANSAC)
  
  h1, w1 = img1.shape[:2]
  h2, w2 = img2.shape[:2]
  
  panorama_width = w1 + w2
  panorama_height = max(h1, h2)
  
  warp = cv.warpPerspective(img2, H, (w1 + w2, h2))
  warp[0:h1, 0:w1] = img1
  img_match=cv.drawMatches(img1,kp1,img2,kp2,good_match,None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
  
  fig, axes = plt.subplots(1, 2, figsize=(20,5))
  axes[0].imshow(warp)
  axes[0].set_title("Warped Image")
  axes[0].axis("off")
  
  axes[1].imshow(img_match)
  axes[1].set_title("Matching Result")
  axes[1].axis("off")
  
  plt.tight_layout()
  plt.show()
   ```
  </details>

   #### ê²°ê³¼ì´ë¯¸ì§€ 
   ![image](https://github.com/user-attachments/assets/d605a8e2-fc97-4570-85e0-553b7b3974bf)







