# ğŸ“Œ L06: Local Feature

## ğŸ“ ê³¼ì œ ë‚´ìš©

### 1. SIFTë¥¼ ì´ìš©í•œ íŠ¹ì§•ì  ê²€ì¶œ ë° ì‹œê°í™”
   1. ì´ë¯¸ì§€ ë¡œë“œ ë° ê·¸ë ˆì´ ìŠ¤ì¼€ì¼ ë³€í™˜
   ```python
  img=cv.imread('L06\img\mot_color70.jpg')
  gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
   ```
   2. SIFT ê°ì²´ ìƒì„±
   - **SIFT(Scale-Invariant Feature Transform)** : ì´ë¯¸ì§€ì˜ í¬ê¸°(scale) ë° íšŒì „(rotation)ì— ì˜í–¥ì„ ë°›ì§€ ì•ŠëŠ” íŠ¹ì§•ì ì„ ì¶”ì¶œí•˜ëŠ” ì•Œê³ ë¦¬ì¦˜
   - nfeatureê°’(ìµœëŒ€ íŠ¹ì§•ì  ìˆ˜)ì„ 1000ê°œë¡œ ì§€ì •
   ```python
  sift=cv.SIFT_create(nfeatures=1000)
   ```
   3. detectAndCompute()ë¥¼ í†µí•´ íŠ¹ì§•ì  ê²€ì¶œ
   - **cv2.Feature2D.detectAndCompute(image, mask=None)**: íŠ¹ì§•ì  ê²€ì¶œê³¼ íŠ¹ì§• ë””ìŠ¤í¬ë¦½í„° ê³„ì‚°ì„ í•œ ë²ˆì— ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
   - image: ì…ë ¥ ì´ë¯¸ì§€, mask: íŠ¹ì§•ì  ê²€ì¶œì— ì‚¬ìš©í•  ë§ˆìŠ¤í¬
   ```python
  kp,des=sift.detectAndCompute(gray,None)
   ```
   4. drawKeypoints()ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§•ì ì„ ì´ë¯¸ì§€ì— ì‹œê°í™”
   - **cv2.drawKeypoints(image, keypoints, outImage, color=None, flags=None)** 
   - image: ì…ë ¥ ì˜ìƒ, keypoints: ê²€ì¶œëœ íŠ¹ì§•ì  ì •ë³´, outImage: ì¶œë ¥ ì˜ìƒ
   - flags: íŠ¹ì§•ì  í‘œí˜„ ë°©ë²• -> DEFAULT(ìœ„ì¹˜ë§Œ í‘œí˜„),**DRAW_RICH_KEYPOINTS(í¬ê¸°ì™€ ë°©í–¥ì„ ë°˜ì˜)**
   ```python
  gray=cv.drawKeypoints(gray,kp,None,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
   ```


  #### ê²°ê³¼ì´ë¯¸ì§€
   ![alt text](image.png)
     
### 2. SIFTë¥¼ ì´ìš©í•œ ë‘ ì˜ìƒ ê°„ íŠ¹ì§•ì  ë§¤ì¹­
   1. ë‘ ì´ë¯¸ì§€ì˜ SIFT íŠ¹ì§•ì  ì¶”ì¶œ
   ```python
  sift=cv.SIFT_create()
  kp1,des1=sift.detectAndCompute(gray1,None)
  kp2,des2=sift.detectAndCompute(gray2,None)
   ```
   2. FlannBasedMatcher()ì„ í†µí•´ íŠ¹ì§•ì  ë§¤ì¹­
   - **cv2.FlannBasedMatcher(indexParams, searchParams)**: FLANN (Fast Library for Approximate Nearest Neighbors) ê¸°ë°˜ Matcher ìƒì„±
   - index_params: íŠ¹ì§•ì  ê²€ìƒ‰ì„ ìœ„í•œ êµ¬ì¡° ì„¤ì • (KD-Tree ì‚¬ìš©)
   - search_params: ê²€ìƒ‰ ê³¼ì •ì—ì„œ ê³ ë ¤í•  ì´ì›ƒ ê°œìˆ˜ ì„¤ì •
   ```python
   index_params = dict(algorithm=1, trees=5)
   search_params = dict(checks=50)
   flann_matcher=cv.FlannBasedMatcher(index_params, search_params)
   ```
   3. ìµœê·¼ì ‘ ì´ì›ƒ ê±°ë¦¬ ë¹„ìœ¨ì„ ì ìš©í•œ KNN ë§¤ì¹­
   - **knnMatch(descripter1,descripter2,k)** : ê° descripterë¥¼ ë¹„êµí•´ kê°œì˜ ìµœê·¼ì ‘ ì´ì›ƒì„ ì°¾ìŒ
   - T=0.7: ê±°ë¦¬ê°€ ê°€ê¹Œìš´ ë‘ ì ì˜ ë¹„ìœ¨ì´ 0.7 ì´í•˜ì¸ ê²½ìš° ì¢‹ì€ ë§¤ì¹­
   ```python
   knn_match=flann_matcher.knnMatch(des1,des2,2)
   T=0.7
   good_match=[]
   for nearest1,nearest2 in knn_match:
      if (nearest1.distance/nearest2.distance)<T:
         good_match.append(nearest1)
   ```
   4. drawMatches()ë¥¼ í†µí•´ ë§¤ì¹­ ê²°ê³¼ë¥¼ ì‹œê°í™”
   - np.empty(): ë‘ ì´ë¯¸ì§€ë¥¼ ë‚˜ë€íˆ ë°°ì¹˜í•˜ê¸° ìœ„í•´ ë¹ˆ ë°°ì—´ì„ ìƒì„±
   - **cv.drawMatches()**: ë§¤ì¹­ëœ íŠ¹ì§•ì ì„ ì‹œê°ì ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ì¶œë ¥
   ```python
   img_match=np.empty((max(img1.shape[0],img2.shape[0]),img1.shape[1]+img2.shape[1],3),dtype=np.uint8)
   cv.drawMatches(img1,kp1,img2,kp2,good_match,img_match,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
   ```
  #### ê²°ê³¼ì´ë¯¸ì§€ 
   ![alt text](image-1.png)
   
### 3. í˜¸ëª¨ê·¸ë˜í”¼ë¥¼ ì´ìš©í•œ ì´ë¯¸ì§€ ì •í•© (Image Alignment)
   1. ë‘ ì´ë¯¸ì§€ì˜ SIFT íŠ¹ì§•ì  ì¶”ì¶œ
   ```python
   sift=cv.SIFT_create()
   kp1,des1=sift.detectAndCompute(gray1,None)
   kp2,des2=sift.detectAndCompute(gray2,None)
   ```
   2. BFMatcher()ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§•ì ì„ ë§¤ì¹­
   - **cv.BFMatcher(normType, crossCheck)**: Brute-Force ë°©ì‹ì˜ Matcher ìƒì„±
   - cv.NORM_L2: SIFTì™€ ê°™ì€ floatí˜• descripterì— ì í•©í•œ ê±°ë¦¬ ì¸¡ì • ë°©ì‹
   - crossCheck=False: KNN ë§¤ì¹­ì„ ì‚¬ìš©í•˜ë¯€ë¡œ í•„ìš”X
   ```python
   bf_matcher=cv.BFMatcher(cv.NORM_L2, crossCheck=False)
   bf_match=bf_matcher.knnMatch(des1, des2, 2)
   ```
   3. findHomography()ë¥¼ í†µí•´ í˜¸ëª¨ê·¸ë˜í”¼ í–‰ë ¬ì„ ê³„ì‚°
   - np.float32(): íŠ¹ì§•ì  ì¢Œí‘œë¥¼ ì‹¤ìˆ˜í˜• ë°°ì—´ë¡œ ë³€í™˜
   - **cv.findHomography(srcPoints, dstPoints, method)**: RANSACì„ ì‚¬ìš©í•˜ì—¬ ë³€í™˜ í–‰ë ¬ Hë¥¼ ê³„ì‚° -> outlier ì œê±°
   ```python
   points1=np.float32([kp1[gm.queryIdx].pt for gm in good_match])
   points2=np.float32([kp2[gm.trainIdx].pt for gm in good_match])

   H, mask = cv.findHomography(points1, points2, cv.RANSAC)
   ```
   4. ì´ë¯¸ì§€ë¥¼ ë³€í™˜í•˜ì—¬ ë‹¤ë¥¸ ì´ë¯¸ì§€ì™€ ì •ë ¬
   - **cv.warpPerspective(img, H, size)**: ì´ë¯¸ì§€ì˜ íˆ¬ì‹œ ë³€í™˜(perspective transformation)ì„ ìˆ˜í–‰
   - ì¶œë ¥ í¬ê¸°ë¥¼ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ì™€ ë™ì¼í•˜ê²Œ ì„¤ì •
   ```python
   h1, w1 = img1.shape[0],img1.shape[1]
   warp= cv.warpPerspective(img2, H, (w1, h1))
   ```
   #### ê²°ê³¼ì´ë¯¸ì§€ 
   ![alt text](image.png)
