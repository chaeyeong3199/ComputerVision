# ğŸ“Œ L07: Recognition

## 1. ê°„ë‹¨í•œ ì´ë¯¸ì§€ ë¶„ë¥˜ê¸° êµ¬í˜„

### 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
   
   ```python
   (x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()
   x_train = x_train.astype("float32") / 255.0
   x_test = x_test.astype("float32") / 255.0
   y_train = utils.to_categorical(y_train)
   y_test = utils.to_categorical(y_test)
   ```
   - TensorFlowì—ì„œ ì œê³µí•˜ëŠ” MNIST ë°ì´í„°ì…‹ì„ ì‚¬ìš©
   - í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• 
   - í”½ì…€ ê°’ì„ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”, ì›-í•« ì¸ì½”ë”©

### 2. ì‹ ê²½ë§ ëª¨ë¸ êµ¬ì¶•

   ```python
   model = models.Sequential()
   model.add(layers.Input(shape=(28, 28)))
   model.add(layers.Flatten())
   model.add(layers.Dense(units=64, activation='relu'))
   model.add(layers.Dense(units=10, activation='softmax'))
   ```
   - ì…ë ¥ì¸µ: 28x28 í”½ì…€ì˜ í‘ë°± ì´ë¯¸ì§€
   - ì€ë‹‰ì¸µ: Dense(64 units, ReLU)
   - ì¶œë ¥ì¸µ: Dense(10 units, Softmax) â€“ 10ê°œì˜ ìˆ«ì ë¶„ë¥˜

### 3. ëª¨ë¸ ì»´íŒŒì¼ ë° í•™ìŠµ
   ```python
   model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
   history = model.fit(x_train, y_train, epochs=7, batch_size=64, verbose=1)
   ```
   - Optimizer: Adam
   - Loss Function: categorical_crossentropy
   - Metric: Accuracy
   - Epochs: 7
   - Batch Size: 64

### 4. ì •í™•ë„ í‰ê°€
   ```python
   loss, acc = model.evaluate(x_test, y_test, verbose=0)
   print(f"ì •í™•ë„: {acc:.4f}")
   ```
![output1-1](https://github.com/user-attachments/assets/4d74ac9c-2a2a-4bb4-96eb-1b0f8a763fd9)

  #### ê²°ê³¼ì´ë¯¸ì§€
![output1-2](https://github.com/user-attachments/assets/02c81197-e90c-4da0-a01c-81a3fa8cc25f)
<br><br><br>
     
## 2. CIFAR-10 ë°ì´í„°ì…‹ì„ í™œìš©í•œ CNN ëª¨ë¸ êµ¬ì¶•

### 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
   ```python
   (x_train, y_train), (x_test, y_test) = cifar10.load_data()
   x_train = x_train.astype("float32") / 255.0
   x_test = x_test.astype("float32") / 255.0
   y_train = tf.keras.utils.to_categorical(y_train, 10)
   y_test = tf.keras.utils.to_categorical(y_test, 10)
   ```
   - ë°ì´í„°ì…‹: CIFAR-10 â€“ ì´ 60,000ê°œì˜ 32x32 RGB ì´ë¯¸ì§€
   - í”½ì…€ ê°’ì„ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”, ì›-í•« ì¸ì½”ë”©

### 2. CNN ëª¨ë¸ êµ¬ì¶•

   ```python
   model = models.Sequential([
      layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
      layers.MaxPooling2D((2, 2)),
      layers.Dropout((0.2)),
      layers.Conv2D(64, (3, 3), activation='relu'),
      layers.MaxPooling2D((2, 2)),
      layers.Conv2D(64, (3, 3), activation='relu'),
      layers.Dropout((0.2)),

      layers.Flatten(),
      layers.Dense(64, activation='relu'),
      layers.Dense(10, activation='softmax')  
   ])
   ```
   - Conv2D + ReLU: íŠ¹ì§• ì¶”ì¶œ
   - MaxPooling2D: ê³µê°„ ì •ë³´ ì¶•ì†Œ
   - Dropout: ê³¼ì í•© ë°©ì§€
   - Flatten + Dense: ë¶„ë¥˜ê¸°(Fully Connected Layers) êµ¬ì„±

### 3. ëª¨ë¸ ì»´íŒŒì¼ ë° í•™ìŠµ

   ```python
   model.compile(optimizer='adam',
               loss='categorical_crossentropy',
               metrics=['accuracy'])

   history = model.fit(x_train, y_train, epochs=20,
                     validation_data=(x_test, y_test),
                     batch_size=64)
   ```
  - Optimizer: Adam
  - Loss Function: categorical_crossentropy
  - Metric: Accuracy
  - Epochs: 20
  - Batch Size: 64
  - Validation Set: í…ŒìŠ¤íŠ¸ì…‹ ì‚¬ìš©

### 4. ì •í™•ë„ í‰ê°€

   ```python
   test_loss, test_acc = model.evaluate(x_test, y_test)
   print(f"\nTest Accuracy: {test_acc:.4f}")
   ```
![output2-1](https://github.com/user-attachments/assets/54f67e6f-05d0-40bb-9456-02d4ea631890)

  ### ì˜ˆì¸¡ê²°ê³¼ ì‹œê°í™” 
![output2-2](https://github.com/user-attachments/assets/6fd3f93c-e4d2-4961-a82c-f66e0e5accd0)
<br><br><br>
   
## 3. ì „ì´ í•™ìŠµì„ í™œìš©í•œ ì´ë¯¸ì§€ ë¶„ë¥˜ê¸° ê°œì„ 

### 1. ë°ì´í„° ì „ì²˜ë¦¬ ë° ì¦ê°•
   
   ```python
   train_dir = 'L07/dataset/train'
   val_dir = 'L07/dataset/val'

   datagen = ImageDataGenerator(
      rescale=1./255,
      rotation_range=20,
      width_shift_range=0.2,
      height_shift_range=0.2,
      horizontal_flip=True
   )

   train_gen = datagen.flow_from_directory(train_dir, target_size=(224, 224), batch_size=16, class_mode='binary')
   val_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(val_dir, target_size=(224, 224), batch_size=16, class_mode='binary')

   ```
   - ì‚¬ìš©ì ì •ì˜ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì´ì§„ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰
   - í•™ìŠµ/ê²€ì¦ ë°ì´í„°ë¥¼ ImageDataGeneratorë¥¼ í†µí•´ ë¶ˆëŸ¬ì˜¤ê³  ì¦ê°•
   - í•™ìŠµ ë°ì´í„°ëŠ” íšŒì „, ì´ë™, ë°˜ì „ ë“±ì„ ì ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ë†’ì„ 

### 2-1. VGG ëª¨ë¸ êµ¬ì¶•

   ```python
   base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
   base.trainable = False
   ```
   - weights='imagenet': ImageNet ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©
   - include_top=False: VGG16ì˜ ìµœìƒìœ„ ë ˆì´ì–´ë¥¼ ì œê±°
   - input_shape=(32, 32, 3): CIFAR-10 ì´ë¯¸ì§€ì— ë§ì¶¤
   - trainable=False: ê°€ì¤‘ì¹˜ë¥¼ ê³ ì •í•˜ì—¬ í•™ìŠµ ì‹œê°„ê³¼ ê³¼ì í•©ì„ ì¤„ì„

### 2-2. VGG ëª¨ë¸ êµ¬ì¶•

   ```python
   model = Sequential([
      base,
      Flatten(),
      Dense(128, activation='relu'),
      Dropout(0.5),
      Dense(1, activation='sigmoid')
   ])
   ```
   - Flatten: VGG16ì—ì„œ ì¶”ì¶œí•œ íŠ¹ì§• ë§µì„ 1ì°¨ì›ìœ¼ë¡œ ë³€í™˜
   - Dense(128): ì€ë‹‰ì¸µìœ¼ë¡œ ê³ ì°¨ì› íŠ¹ì§• ì¡°í•©
   - Dropout(0.5): í•™ìŠµ ì‹œ 50% ë‰´ëŸ° ë¬´ì‘ìœ„ ë¹„í™œì„±í™”
   - Dense(1, activation='sigmoid'): sigmoidë¡œ ì´ì§„ ë¶„ë¥˜ ìˆ˜í–‰

### 3. ëª¨ë¸ ì»´íŒŒì¼ ë° í•™ìŠµ
   ```python
   model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
   history = model.fit(train_gen, epochs=10, validation_data=val_gen)
   ```
   - ì†ì‹¤ í•¨ìˆ˜: binary_crossentropy
   - optimizer: adam
   - í‰ê°€ì§€í‘œ: accuracy
   - Epochs: 10

### 4. ì •í™•ë„ í‰ê°€
   ```python
   loss, acc = model.evaluate(x_test, y_test, verbose=0)
   print(f"ì •í™•ë„: {acc:.4f}")
   ```
- VGG ëª¨ë¸ ì •í™•ë„ <br>

![image](https://github.com/user-attachments/assets/6468d63c-f32c-450d-9bc7-051c1af32325)
- CNN ëª¨ë¸ ì •í™•ë„ <br>

![image](https://github.com/user-attachments/assets/aed0db98-ed93-4f98-a8d7-a082f7d7fdbd)

### ê²°ê³¼ ì´ë¯¸ì§€ (VGG vs CNN)
![image](https://github.com/user-attachments/assets/b627f294-120d-46bb-a48c-5930555f4a82) ![image](https://github.com/user-attachments/assets/de9e2d03-7396-493a-9c93-c87d3c9ac962)


